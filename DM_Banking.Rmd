---
title: "Data Mining on Bank Marketing Data"
author: "Stephan Sprenger"
date: "25 October 2014"
output: html_document
---

# Introduction

The data investigated in this small workbook goes back to _S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014_  
The data is available from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing). Several data sets are available; we will use the ```bank-additional-full.csv```.
An earlier paper from the authors is _Moro, Cortez, Laureano: A data mining approach for bank telemarketing using the rminer package and r tool_ [here](http://bru-unide.iscte.pt/RePEc/pdfs/13-06.pdf).

The purpose of this workbook to apply different machine learning algorithms to the data problem. The software ```R``` will be used in conjunction with the package ```caret```.


# Data Preparation

The data is being loaded (agian, we will use the ```bank-additional-full.csv```).  
Investigation shows that the data needs to be prepared for analysis.
The following steps are performed:

* the financial indicators are "factor"", while we would want to have them as numeric for analysis. Therefore this data is transformed.
* We also understand that there are "unknown" data in several variables. We could replace these with NAs; however some algorithms (like Naive Bayes) would struggle. Given that on some of these variables there are many unknowns (like for ```pdays```) we will leave the unknown observations as an own category "unknown".   
* The variable ```pdays``` has a value of 999 for 'not available'; wee will set this to "unknown" as well.

One important change we make is with regards to the the variable ```duration```. It indicates the length of a call. This might be interesting for analysis, but difficult for prediction: In a prediction task we do not know the duration of the call before it actually takes place.  
Therefore ```duration``` is being excluded from the set of predictors; this seems to be different from a lot of other research on this data set.  

Also the data set is split into a training set (80%) and a test set (20%). 

```{r load data}
library(caret)
bank.raw <- read.csv2(file="bank-additional-full.csv")
str(bank.raw)
bank <- bank.raw
bank$job <- factor(gsub("\\-", "", bank$job))
bank[,16:20] <- apply(bank[,16:20], 2, function (x) as.numeric(as.character(x)))
#bank[bank=="unknown"] <- NA
bank <- droplevels(bank)
bank[bank$pdays==999,"pdays"] <- "unknown"
bank$pdays <- as.factor(bank$pdays)
summary(bank)
names(bank)[names(bank)=="y"] <- "success"
bank$success <- factor(bank$success, levels=c("yes", "no"))

bank <- subset(bank, select=-c(duration))

trainIndex <- createDataPartition(bank$success, p=0.8, list=FALSE, times=1)
bank.train <- bank[trainIndex,]
bank.test <- bank[-trainIndex,]

```

# Data Exploration

Visual exploration 

```{r explo}
library(vcd)
mosaic(  ~  success+poutcome, data=bank, shade=TRUE, main="Success of campaign vs previous successes")
hist(bank$euribor3m)
library(ggplot2)
ggplot(data=bank, aes(x=euribor3m, fill=success)) + geom_histogram(alpha=0.5, position="dodge")
```

# Modelling

```{r modeling}
Sys.time()
bank.train.data <- subset(bank.train, select=-c(success), drop=TRUE)
bank.train.class <- subset(bank.train, select=c(success), drop=TRUE)
bank.test.data <- subset(bank.test, select=-c(success), drop=TRUE)
bank.test.class <- subset(bank.test, select=c(success), drop=TRUE)


cvCtrl <- trainControl(method="cv", classProbs=TRUE, summaryFunction=twoClassSummary, verboseIter=TRUE)
#splCtrl <- trainControl(method="none", classProbs = TRUE)


fit.rpart <- train(bank.train.data, bank.train.class, method="rpart", trControl=cvCtrl, metric="ROC", tuneLength = 10)
predict.rpart <- predict(fit.rpart)
confusionMatrix(predict.rpart, bank.train.class, positive="yes")
predict.rpart <- predict(fit.rpart, type = "prob")
(auc.rpart <- auc(bank.train.class, predict.rpart$yes))
predict.rpart <- predict(fit.rpart, bank.test.data, type = "prob")
(auc.rpart <- auc(bank.test.class, predict.rpart$yes))



#fit.c50 <- train(bank.train.data, bank.train.class, method="C5.0", trControl=cvCtrl, metric="ROC", tuneLength = 10)
load(file="C50_CV_10Iter.RData")
predict.c50 <- predict(fit.c50)
confusionMatrix(predict.c50, bank.train.class, positive="yes")
predict.c50 <- predict(fit.c50, type = "prob")
(auc.c50 <- auc(bank.train.class, predict.c50$yes))
predict.c50 <- predict(fit.c50, bank.test.data, type="prob")
(auc.c50 <- auc(bank.test.class, predict.c50$yes))


#fit.ctree <- train(bank.train.data, bank.train.class, method="ctree", trControl=cvCtrl, metric="ROC")
load(file = "Ctree_CV_10Iter.RData")
predict.ctree <- predict(fit.ctree)
confusionMatrix(predict.ctree, bank.train.class, positive="yes")
predict.ctree <- predict(fit.ctree, type = "prob")
(auc.ctree <- auc(bank.train.class, predict.ctree$yes))
predict.ctree <- predict(fit.ctree, bank.test.data, type="prob")
(auc.ctree <- auc(bank.test.class, predict.ctree$yes))

bank.train.dummy <- predict(dummyVars(success ~ . ,data=bank.train), newdata=bank.train)
bank.train.dummy <- data.frame(bank.train.dummy, success=factor(bank.train$success))
bank.test.dummy <- predict(dummyVars(success ~ . ,data=bank.test), newdata=bank.test)
bank.test.dummy <- data.frame(bank.test.dummy, success=factor(bank.test$success))


#fit.logit <- train(success ~ ., data=bank.train.dummy, method="glm", family=binomial, trControl=cvCtrl, metric="ROC", tuneLength=1)
load(file = "Logit_CV_10Iter.RData")
predict.logit <- predict.train(fit.logit)
confusionMatrix(predict.logit, bank.train.class, positive="yes")
predict.logit <- predict(fit.logit, type = "prob")
(auc.logit <- auc(bank.train.dummy$success, predict.logit$yes))
predict.logit <- predict(fit.logit, bank.test.dummy, type="prob")
(auc.logit <- auc(bank.test.dummy$success, predict.logit$yes))

#fit.nb <- train(bank.train.data, bank.train.class, method="nb", trControl=cvCtrl, metric="ROC", tuneLength=10)
load(file = "NB_CV_10Iter.RData")
predict.nb <- predict(fit.nb)
confusionMatrix(predict.nb, bank.train.class, positive="yes")
predict.nb <- predict(fit.nb, type = "prob")
(auc.nb <- auc(bank.train.class, predict.nb$yes))
predict.nb <- predict(fit.nb, bank.test.data, type="prob")
(auc.nb <- auc(bank.test.class, predict.nb$yes))


#fit.nn <- train(success ~ ., data=bank.train.dummy, method="nnet", trControl=cvCtrl, metric="ROC", tuneLength=10)
load(file = "NN_CV_10Iter.RData")
predict.nn <- predict(fit.nn)
confusionMatrix(predict.nn, bank.train.class, positive="yes")
predict.nn <- predict(fit.nn, type = "prob")
(auc.nn <- auc(bank.train.class, predict.nn$yes))
predict.nn <- predict(fit.nn, bank.test.dummy, type="prob")
(auc.nn <- auc(bank.test.class, predict.nn$yes))


plot.roc(bank.test.class, predict.rpart$yes, col="green")
lines.roc(bank.test.class, predict.c50$yes, col="blue")
lines.roc(bank.test.class, predict.ctree$yes, col="pink")
lines.roc(bank.test.class, predict.nb$yes, col="red")
lines.roc(bank.test.class, predict.logit$yes, col="orange")
lines.roc(bank.test.class, predict.nn$yes, col="cyan")
legend("bottomright", legend=c("CART", "C50", "Cond. Inference Trees", "Naive Bayes", "Logit", "Neural Net"), col=c("green", "blue", "pink", "red", "orange", "cyan"), lwd=2, cex=0.5)

library(dplyr)
auc <- rbind(C50=auc.c50, CART=auc.rpart, ctree=auc.ctree, Logit=auc.logit, NaiveBayes=auc.nb, NeuralNet=auc.nn)
auc <- data.frame(Model=row.names(auc), AUC=auc)
(auc <- arrange(auc, desc(AUC)))


Sys.time()
plot(varImp(fit.rpart))
plot(varImp(fit.c50))
plot(varImp(fit.ctree))
plot(varImp(fit.nb))
plot(varImp(fit.logit))
plot(varImp(fit.nn))
```



```{r compare}
#compare different models
modelObjects <- list(cart=fit.rpart,
                     c50=fit.c50,
                     ctree=fit.ctree,
                     nb=fit.nb,
                     logit=fit.logit,
                     nn=fit.nn)
#predict(modelObjects, churnTrain)

x <- data.frame(ROC=sort(sapply(modelObjects, function(x) max(x$results$ROC)), decreasing=TRUE))
x
# variances in resamples.
cvValues <- resamples(list(CART=fit.rpart, C50=fit.c50, ctree=fit.ctree, logit=fit.logit, naivebayes=fit.nb, neuralnet=fit.nn))
summary(cvValues)
dotplot(cvValues)
```

